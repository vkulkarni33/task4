{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXCJQCClu5cp",
        "outputId": "de0072b4-7570-4e56-fb5c-68fd11642a99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unzip\n",
            "  Downloading unzip-1.0.0.tar.gz (704 bytes)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: unzip\n",
            "  Building wheel for unzip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unzip: filename=unzip-1.0.0-py3-none-any.whl size=1283 sha256=d005a686631dfd6f978ee9dea9078a04544192168dbc43cdcadc984626d3cc3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/dc/7a/f8af45bc239e7933509183f038ea8d46f3610aab82b35369f4\n",
            "Successfully built unzip\n",
            "Installing collected packages: unzip\n",
            "Successfully installed unzip-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/archive (9).zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_data')"
      ],
      "metadata": {
        "id": "SscIJCrPvD3g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAcBDLOOtsjx",
        "outputId": "a77da6a8-947c-4f18-c1bb-f56bb99005ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (569, 32)\n",
            "Columns: Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst'],\n",
            "      dtype='object')\n",
            "Train set size: 398, Test set size: 171\n",
            "\n",
            "Feature Set Shape: (569, 31)\n",
            "Target Variable Distribution:\n",
            " diagnosis\n",
            "0    357\n",
            "1    212\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Step 1: Unzip and load the dataset\n",
        " # Assuming the first file is the dataset\n",
        "\n",
        "# Load the data into a pandas DataFrame\n",
        "data_path = '/content/extracted_data/breast-cancer.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "# Step 2: Explore the dataset\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns)\n",
        "\n",
        "# Step 3: Handle missing values (if any)\n",
        "df = df.dropna()  # Dropping rows with missing values for simplicity\n",
        "\n",
        "# Step 4: Encode the target variable\n",
        "target_column = 'diagnosis'  # Adjust this to match the actual target column name\n",
        "df[target_column] = LabelEncoder().fit_transform(df[target_column])  # 0 = benign, 1 = malignant\n",
        "\n",
        "# Step 5: Define features (X) and target (y)\n",
        "X = df.drop([target_column], axis=1)  # Exclude the target column\n",
        "y = df[target_column]\n",
        "\n",
        "# Step 6: Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 7: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "print(f\"Train set size: {len(X_train)}, Test set size: {len(X_test)}\")\n",
        "\n",
        "# Step 8: Output a summary of processed data\n",
        "print(\"\\nFeature Set Shape:\", X.shape)\n",
        "print(\"Target Variable Distribution:\\n\", y.value_counts())\n"
      ]
    }
  ]
}